{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid-19_Transaction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLYSm_TKuHYe"
      },
      "source": [
        "from os import chdir,listdir\n",
        "import glob\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization,Concatenate\n",
        "from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import plot_roc_curve, roc_curve, auc\n",
        "from scikitplot.metrics import plot_confusion_matrix,plot_roc\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score,classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score,classification_report\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f-gGg9hwscj"
      },
      "source": [
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "def transform_images(images: np.ndarray):\n",
        "    \"\"\"\n",
        "    Transform images to [-1, 1]\n",
        "    \"\"\"\n",
        "    images = 2*images.astype(np.float32) -1\n",
        "    return images\n",
        "\n",
        "def load_covid_data(image_size=150, path='../Data/train',shuffle=False,class_frequency=False):\n",
        "    \n",
        "    size = image_size\n",
        "    files = listdir(path)\n",
        "    X = []\n",
        "    Y = []\n",
        "    \n",
        "    for direct in files:\n",
        "        files_in_folder = glob.glob(path+'/'+direct+'/*.jpg')\n",
        "        for file in files_in_folder:\n",
        "            data = plt.imread(file)\n",
        "            data = cv2.resize(data, (size, size))\n",
        "            data = data.astype('float32') / 255\n",
        "            if len(data.shape)>2 and data.shape[2] == 3:\n",
        "                data = rgb2gray(data)\n",
        "            if len(data.shape)>2 and data.shape[2] == 4:\n",
        "                data = cv2.cvtColor(data, cv2.COLOR_BGRA2BGR)\n",
        "                data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n",
        "                data = rgb2gray(data)\n",
        "            X.append(data)       \n",
        "            Y.append(direct)\n",
        "    \n",
        "    print(len(X))\n",
        "    X = np.array(X).astype(float)\n",
        "    X = transform_images(X)\n",
        "    X = X[:, :, :, None]\n",
        "    \n",
        "    le=LabelEncoder()\n",
        "    Y=le.fit_transform(Y)\n",
        "    Y=np.array(Y).astype(float)\n",
        "    Y=to_categorical(Y,len(files))\n",
        "\n",
        "    if shuffle:\n",
        "       idx = np.random.choice(len(X),size=len(X), replace=False)\n",
        "       X=X[idx,:,:]\n",
        "       Y=Y[idx,:]\n",
        "    if class_frequency:\n",
        "       classes =le.inverse_transform(np.argmax(Y,axis=1).astype(int))\n",
        "       unique, counts = np.unique(classes, return_counts=True)\n",
        "       counts=np.array(counts)\n",
        "       plt.bar(unique,counts)\n",
        "       plt.title('Class Frequency(Percent)')\n",
        "       plt.xlabel('Class')\n",
        "       plt.ylabel('Frequency')\n",
        "       plt.show()\n",
        "    \n",
        "    return X, Y\n",
        "\n",
        "image_size=150\n",
        "x_train, y_train=load_covid_data(image_size, path='Data/train',shuffle=True,class_frequency=True)\n",
        "x_test,y_test=load_covid_data(image_size, path='Data/test')\n",
        "\n",
        "#x_train_gan,y_train_gan=load_covid_data(image_size, path='drive/My Drive/Chest_Covid/Data_Gan')\n",
        "\n",
        "class_weights = compute_class_weight('balanced',np.unique(np.argmax(y_train,axis=1)),np.argmax(y_train,axis=1))\n",
        "class_weights={0:class_weights[0],\n",
        "               1:class_weights[1],\n",
        "               2:class_weights[2]}\n",
        "#x_train_augmented=np.concatenate((x_train,x_train_gan),axis=0)\n",
        "#y_train_augmented=np.concatenate((y_train,y_train_gan),axis=0)\n",
        "\n",
        "#unique, counts = np.unique(np.argmax(y_train_augmented,axis=1).astype(int), return_counts=True)\n",
        "#counts=np.array(counts)\n",
        "#plt.bar(unique,counts)\n",
        "#plt.title('Class Frequency(Percent)')\n",
        "#plt.xlabel('Class')\n",
        "#plt.ylabel('Frequency')\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "def create_dataset(augmentation,BATCH_SIZE=32):\n",
        "  if augmentation:\n",
        "     train_dataset = tf.data.Dataset.from_tensor_slices((x_train_augmented, y_train_augmented))\n",
        "     train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "     train_dataset = train_dataset.cache()\n",
        "     train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  else:\n",
        "     train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "     train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "     train_dataset = train_dataset.cache()\n",
        "     train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  validation_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "  validation_dataset = validation_dataset.batch(BATCH_SIZE)\n",
        "  validation_dataset = validation_dataset.cache()\n",
        "  validation_dataset = validation_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  return train_dataset,validation_dataset\n",
        "\n",
        "train_dataset,validation_dataset=create_dataset(augmentation=False,BATCH_SIZE=128)\n",
        "#train_dataset_augmented,validation_dataset_augmented=create_dataset(augmentation=True,BATCH_SIZE=32)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDt1r6LPwshN"
      },
      "source": [
        "#new_idea\n",
        "image_size=150\n",
        "def get_dropout(input_tensor, rate, mc=False):\n",
        "    if mc:\n",
        "        return Dropout(rate=rate)(input_tensor, training=True)\n",
        "    else:\n",
        "        return Dropout(rate=rate)(input_tensor)\n",
        "\n",
        "def get_model(mc,lr=0.00005):\n",
        "    inputs = Input(shape=(image_size, image_size, 1))\n",
        "    input2=tf.stack([inputs, inputs, inputs],axis=3)[:,:,:,:,0]\n",
        "    vgg_model = tf.keras.applications.VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(image_size, image_size, 3))\n",
        "    vgg_model.trainable=False\n",
        "\n",
        "    Vgg_feature=vgg_model(input2)\n",
        "    # First conv block\n",
        "    conv1 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(conv1)\n",
        "    conv1 = MaxPool2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "   #Second conv block\n",
        "    conv2 = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(conv1)\n",
        "    conv2 = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = MaxPool2D(pool_size=(2, 2))(conv2)\n",
        "   # Third conv block\n",
        "    conv3 = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(conv2)\n",
        "    conv3 = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = MaxPool2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "  # Fourth conv block\n",
        "    conv4 = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(conv3)\n",
        "    conv4 = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same',name='target_layer')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = MaxPool2D(pool_size=(2, 2))(conv4)\n",
        "    conv4=get_dropout(conv4, rate=0.2, mc=mc)\n",
        "\n",
        "   # Fifth conv block\n",
        "    conv5 = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(conv4)\n",
        "    conv5 = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = MaxPool2D(pool_size=(2, 2))(conv5)\n",
        "    conv5=get_dropout(conv5, rate=0.2, mc=mc)\n",
        "\n",
        "    concatenated_tensor = Concatenate(axis=1)([Flatten()(conv3), Flatten()(conv4), Flatten()(conv5),Flatten()(Vgg_feature)])\n",
        "\n",
        "    # FC layer\n",
        "    x = Flatten()(concatenated_tensor)\n",
        "    x = Dense(units=512, activation='relu')(x)\n",
        "\n",
        "    x=get_dropout(x, rate=0.7, mc=mc)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "    x=get_dropout(x, rate=0.5, mc=mc)\n",
        "    x = Dense(units=64, activation='relu')(x)\n",
        "    x=get_dropout(x, rate=0.3, mc=mc)\n",
        "   # Output layer\n",
        "    output = Dense(3, activation='softmax')(x)\n",
        "    METRICS = [\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc')]\n",
        "   # Creating model and compiling\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    adam = tf.keras.optimizers.Adam(lr=lr)\n",
        "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy',METRICS])\n",
        "    # Callbacks\n",
        "    if mc:\n",
        "      mcheck = ModelCheckpoint('model_covid_mc.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "    else:\n",
        "      mcheck = ModelCheckpoint('model_covid_simple.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.8,verbose=1,patience=5)\n",
        "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=0, patience=30)\n",
        "    callbacks=[reduce_lr,es,mcheck]\n",
        "\n",
        "    return model,callbacks\n",
        "\n",
        "mc_model,mc_callbacks=get_model(mc=True)\n",
        "simple_model,simple_callbacks=get_model(mc=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBHioGitwslJ"
      },
      "source": [
        "train_dataset,validation_dataset=create_dataset(augmentation=False,BATCH_SIZE=32)\n",
        "train_dataset_augmented,validation_dataset=create_dataset(augmentation=False,BATCH_SIZE=128)\n",
        "mc_model,mc_callbacks=get_model(mc=True,lr=5e-4)\n",
        "hist_mc = mc_model.fit(train_dataset_augmented,epochs=200,validation_data=validation_dataset,\n",
        "                          class_weight=class_weights,callbacks=mc_callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0I01E4Dwsoo"
      },
      "source": [
        "mc_model=load_model('Chest_Covid/model_covid_mc.h5')\n",
        "\n",
        "mean_coef=[1,1,1,1,1,1,1,1]\n",
        "std_coef=[1e-4,1e-3,1e-2,1e-1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,\n",
        "          1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2]\n",
        "\n",
        "def mode_robustness(x_test,y_test,model,std_coef):\n",
        "  result=[]\n",
        "  for std in std_coef:\n",
        "    #for i in range(len(np.unique(y_test.argmax(axis=1)))):\n",
        "        #idx=np.where(np.argmax(y_test,axis=1)==i)[0]\n",
        "        #y_class=y_test[idx,:]\n",
        "        #x_class=x_test[idx,:,:,:]\n",
        "        y_class=y_test\n",
        "        x_class=x_test\n",
        "        mean=np.mean(x_class)*0\n",
        "        sigma=np.std(x_class)*std\n",
        "        gaussian = np.random.normal(mean, sigma, x_class.shape)\n",
        "        x_class=x_class+gaussian\n",
        "        y_p_class=model.predict(x_class)\n",
        "        acc = accuracy_score(np.argmax(y_class,axis=1), np.argmax(y_p_class,axis=1))\n",
        "        precision = precision_score(np.argmax(y_class,axis=1), np.argmax(y_p_class,axis=1),average='weighted')\n",
        "        recall = recall_score(np.argmax(y_class,axis=1), np.argmax(y_p_class,axis=1),average='weighted')\n",
        "        F1=(2*precision*recall)/(precision+recall)\n",
        "        result.append([std,acc,precision,recall,F1])\n",
        "  \n",
        "  return result    \n",
        "\n",
        "result=mode_robustness(x_test,y_test,mc_model,std_coef)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvwvU0IMDfKd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__a85WNYDfQU"
      },
      "source": [
        "import matplotlib \n",
        "matplotlib.rc('xtick', labelsize=22) \n",
        "matplotlib.rc('ytick', labelsize=22)\n",
        "plt.rcParams.update({'font.size': 22})\n",
        "\n",
        "def plot_roc_handy(y_test,y_score,lw=2,Name='Roc',calss_name=['COVID19','Normal','Pneumonia'],zoom=False):\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    #y_score=np.array(mc_predictions).mean(axis=0)\n",
        "    for i in range(int(y_test.shape[1])):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(int(y_test.shape[1]))]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(int(y_test.shape[1])):\n",
        "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "    mean_tpr /= int(y_test.shape[1])\n",
        "    fpr[\"macro\"] = all_fpr\n",
        "    tpr[\"macro\"] = mean_tpr\n",
        "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "    \n",
        "    f, ax = plt.subplots(figsize=[15, 15])\n",
        "    #f =plt.figure(figsize=(15, 15))\n",
        "    ax.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "    ax.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "    for i, color in zip(range(int(y_test.shape[1])), colors):\n",
        "       ax.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(calss_name[i], roc_auc[i]))\n",
        "    ax.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "    ax.set_xlim([0.001, 1.0])\n",
        "    ax.set_ylim([0, 1.05])\n",
        "    ax.set_xlabel('False Positive Rate',fontsize=22)\n",
        "    ax.set_ylabel('True Positive Rate',fontsize=22)\n",
        "    ax.set_title(Name,fontsize=22)\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    \n",
        "    # inset axes....\n",
        "    if zoom:\n",
        "       axins = ax.inset_axes([0.3, 0.5, 0.4, 0.4])\n",
        "       for i, color in zip(range(int(y_test.shape[1])), colors):\n",
        "           if fpr[i].all()<0.2 and tpr[i].all()<0.95:\n",
        "              axins.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "               label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                ''.format(calss_name[i], roc_auc[i]))\n",
        "               \n",
        "              axins.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "               color='deeppink', linestyle=':', linewidth=4)\n",
        "              \n",
        "              axins.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "                 label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "                color='navy', linestyle=':', linewidth=4)\n",
        "               \n",
        "       #x1, x2, y1, y2 = 0, 0.2, 0.96, 0.96\n",
        "       x1, x2, y1, y2 = 0.01, 0.3, 0.9, 1.01\n",
        "       axins.set_xlim(x1, x2)\n",
        "       axins.set_ylim(y1, y2)\n",
        "       axins.set_xticklabels('')\n",
        "       axins.set_yticklabels('')\n",
        "       ax.indicate_inset_zoom(axins)\n",
        "\n",
        "    plt.show()\n",
        "    f.savefig('{}.pdf'.format(Name))\n",
        "    ax.figure.savefig(\"{}.pdf\".format(Name), bbox_inches='tight')\n",
        "#y_p\n",
        "#np.array(mc_predictions).mean(axis=0)\n",
        "plot_roc_handy(y_test,y_pred ,zoom=True,lw=2,Name='ROC of Random Forest (X-Ray)',\n",
        "               calss_name=['COVID19','Normal','Pneumonia'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MyPNXddDf7l"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "def plot_CM_handy(y_test,y_score,lw=2,Name='Confusion Matrix of Fusion Model without Uncertainty (X-Ray)',classes=['COVID19','Normal','Pneumonia']):\n",
        "    CM=confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_score,axis=1))\n",
        "    cm=CM\n",
        "    cmap=plt.cm.Blues\n",
        "    fig, ax = plt.subplots(figsize=(6,6),dpi=80, facecolor='w', edgecolor='k')\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.set_title(Name)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           ylabel='True Label',\n",
        "           xlabel='Predicted Label')\n",
        "    ax.set_xticklabels(classes,fontsize=15)\n",
        "    ax.set_yticklabels(classes,fontsize=15)\n",
        "    ax.set_ylabel('True Label',fontsize=15)\n",
        "    ax.set_xlabel('Predicted Label',fontsize=15)\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "    fmt = '.1f' \n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "           figure(num=None, figsize=(5, 5), dpi=80, facecolor='w', edgecolor='k')\n",
        "           ax.text(j, i, format(cm[i, j], fmt),fontsize=12,\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    fig.savefig('{}.pdf'.format(Name),dpi=300)\n",
        "    ax.figure.savefig(\"{}.pdf\".format(Name), bbox_inches='tight')\n",
        "  #fig.savefig('CM.png', dpi=300)\n",
        "\n",
        "plot_CM_handy(y_test,y_pred,\n",
        "              lw=2,Name='Confusion Matrix of Decision Tree (X-Ray)',\n",
        "              classes=['COVID19','Normal','Pneumonia'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpBh2zQ4Dlym"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Z72sSjDl5v"
      },
      "source": [
        "\n",
        "def evaluation(y_test,y_pred):\n",
        "     acc = accuracy_score(y_test, y_pred)\n",
        "     precision = precision_score(y_test, y_pred,average='weighted')\n",
        "     recall = recall_score(y_test, y_pred,average='weighted')\n",
        "     F1=(2*precision*recall)/(precision+recall)\n",
        "     return acc,precision,recall,F1\n",
        "\n",
        "\n",
        "\n",
        "x_train_statistical=x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]*x_train.shape[3])\n",
        "y_train_statistical=np.argmax(y_train,axis=1)\n",
        "x_test_statistical=x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3])\n",
        "y_test_statistical=np.argmax(y_test,axis=1)\n",
        "\n",
        "classifier1=DecisionTreeClassifier(max_depth=50,class_weight='balanced')\n",
        "param_grid_dt = {'max_depth':[50,100,150,200,300]}\n",
        "grid = GridSearchCV(DecisionTreeClassifier(class_weight='balanced',random_state=0) ,param_grid_dt,cv=3)\n",
        "classifier1.fit(x_train_statistical, y_train_statistical)\n",
        "print('Best params of dt is:',grid.get_params)\n",
        "classifier1=grid.best_estimator_\n",
        "y_pred_dt=classifier1.predict(x_test_statistical)\n",
        "acc,precision,recall,F1=evaluation(y_test_statistical,y_pred_dt)\n",
        "print('Dt test results are:',evaluation(y_test_statistical,y_pred_dt))\n",
        "print('Dt train results are:',evaluation(y_train_statistical,classifier1.predict(x_train_statistical)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58FlsByyD70e"
      },
      "source": [
        "classifier2=RandomForestClassifier(max_depth=50,n_estimators=200,class_weight='balanced',random_state=0)\n",
        "classifier2.fit(x_train_statistical, y_train_statistical)\n",
        "#print('Best params of dt is:',grid.get_params)\n",
        "#classifier1=grid.best_estimator_\n",
        "y_pred_rf=classifier2.predict(x_test_statistical)\n",
        "acc,precision,recall,F1=evaluation(y_test_statistical,y_pred_rf)\n",
        "print('Rf test results are:',evaluation(y_test_statistical,y_pred_rf))\n",
        "print('Rf train results are:',evaluation(y_train_statistical,classifier1.predict(x_train_statistical)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHiMIOFxDmA8"
      },
      "source": [
        "from sklearn.metrics import plot_roc_curve, roc_curve, auc\n",
        "from scikitplot.metrics import plot_confusion_matrix,plot_roc\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "\n",
        "#plot_roc(y_test_statistical, classifier1.predict_proba(x_test_statistical),title=\"Decision Tree (X-Ray)\")\n",
        "#plot_roc(y_test_statistical, classifier2.predict_proba(x_test_statistical),title=\"Random Forest (X-Ray)\")\n",
        "plot_roc_handy(y_test, y_p,lw=2,Name='Roc of fusion model without uncertainty (X-Ray)',\n",
        "               calss_name=['COVID19','Normal','Pneumonia'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxLz4xjXD4X-"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "mc_model=load_model('Chest_Covid/model_covid_mc.h5')\n",
        "number_prediction=200\n",
        "mc_predictions = []\n",
        "for i in tqdm.tqdm(range(number_prediction)):\n",
        "    y_p = mc_model.predict(x_test,batch_size=256)\n",
        "    mc_predictions.append(y_p)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}